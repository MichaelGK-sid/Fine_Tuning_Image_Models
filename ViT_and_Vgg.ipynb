{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Important imports"
      ],
      "metadata": {
        "id": "w8f7gFOt4NXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xof2RPM3qnB4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to unzip a zip file that contains the training data."
      ],
      "metadata": {
        "id": "bN0Xjxhf4SkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"face\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(data_path / \"face.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"face.zip\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCk2nVMTqvCB",
        "outputId": "b7b71711-9b88-4270-b031-d82e8a2ee7f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/face directory exists.\n",
            "Unzipping data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to transform the datapoints(images), create datasets and dataloaders."
      ],
      "metadata": {
        "id": "YWKWbuHj4cUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "train_dir = Path(\"data/face/train/\")\n",
        "test_dir = Path(\"data/face/test/\")\n",
        "IMG_SIZE = 224\n",
        "# Create transform pipeline manually\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),      # Resize to 224x224\n",
        "    transforms.ToTensor(),              # Convert to tensor [0,1]\n",
        "    transforms.RandomRotation(9),\n",
        "    transforms.Normalize(               # Normalize using ImageNet stats\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Use ImageFolder to create dataset(s)\n",
        "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Get class names\n",
        "class_names = train_data.classes\n",
        "\n",
        "# Turn images into data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, # don't need to shuffle test data\n",
        "    pin_memory=True,)"
      ],
      "metadata": {
        "id": "fRf8ZhMvMj0S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to load a pretrained ViT (Vision Transformer model) from torchvision.models, freeze all the parameters so that the training doesn't affect them, and replace the classification head so that it output matches the number of classes of that specific problem.\n"
      ],
      "metadata": {
        "id": "7K9cECZb4-e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Load the pretrained ViT model\n",
        "model = models.vit_b_16(pretrained=True)\n",
        "\n",
        "# Freeze the feature extractor\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the classification head for 7 classes\n",
        "model.heads = nn.Sequential(\n",
        "    nn.Linear(model.hidden_dim, 7)\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Loss function and optimizer (only train classifier head)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.heads.parameters(), lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X38eWItFLgBb",
        "outputId": "9b85feb8-e8e2-4ab4-da0e-b1307a1f9051"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop"
      ],
      "metadata": {
        "id": "kz4um1hx8lSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZyXPsWVLl6i",
        "outputId": "6cef2dd2-6e56-4eec-f5d0-5b6e1e9a9e8c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.2538, Accuracy: 52.76%\n",
            "Epoch 2/10, Loss: 1.0590, Accuracy: 61.01%\n",
            "Epoch 3/10, Loss: 0.9905, Accuracy: 63.79%\n",
            "Epoch 4/10, Loss: 0.9485, Accuracy: 65.22%\n",
            "Epoch 5/10, Loss: 0.9177, Accuracy: 66.21%\n",
            "Epoch 6/10, Loss: 0.8998, Accuracy: 66.89%\n",
            "Epoch 7/10, Loss: 0.8776, Accuracy: 68.08%\n",
            "Epoch 8/10, Loss: 0.8598, Accuracy: 68.68%\n",
            "Epoch 9/10, Loss: 0.8566, Accuracy: 68.95%\n",
            "Epoch 10/10, Loss: 0.8352, Accuracy: 69.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to put the model into evaluation mode, use torch.no_grad() and calculate the validation/test accuracy by using data from from the test dataloader."
      ],
      "metadata": {
        "id": "Xu9VgVfq8rlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Validation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "val_accuracy = correct / total * 100\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlKCg1GhLn3g",
        "outputId": "3ddea06f-ec9a-4e8d-a691-53c476c59eba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 67.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to load a pretrained VGG model from torchvision.models, freeze all the parameters so that the training doesn't affect them, and replace the classification head so that it output matches the number of classes of that specific problem."
      ],
      "metadata": {
        "id": "5sqZUdur8--k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg11(pretrained=True)\n",
        "\n",
        "# Freeze all feature extractor layers\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the classifier for 7 classes\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(25088, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(4096, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(1024, 7)  # 7 classes\n",
        ")\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer (train only classifier)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo_-5iXzWRFP",
        "outputId": "0db2f840-9d61-4609-9cb5-b5a0187fb687"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 507M/507M [00:03<00:00, 175MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop"
      ],
      "metadata": {
        "id": "PwY8Hf7X9Zx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRKeu4l1eT6s",
        "outputId": "512d88cb-f5aa-4c55-e9ad-81c2ba167cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.2445, Accuracy: 56.95%\n",
            "Epoch 2/10, Loss: 0.8708, Accuracy: 68.86%\n",
            "Epoch 3/10, Loss: 0.7743, Accuracy: 72.80%\n",
            "Epoch 4/10, Loss: 0.6912, Accuracy: 75.59%\n",
            "Epoch 5/10, Loss: 0.6377, Accuracy: 77.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to save the weights of a model via a .pth (.pt) file"
      ],
      "metadata": {
        "id": "j5_zWq0A9dRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': epoch_loss,\n",
        "}, 'vgg11_checkpoint.pth')"
      ],
      "metadata": {
        "id": "IL8RrBQZkz1l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to load the weights of a model which has been saved in a .pth file."
      ],
      "metadata": {
        "id": "0nL6wdaK9l5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and optimizer\n",
        "checkpoint = torch.load('vgg11_checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Optional: resume from the next epoch\n",
        "start_epoch = checkpoint['epoch'] + 1"
      ],
      "metadata": {
        "id": "jkzX9atzlQA8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to put the model into evaluation mode, use torch.no_grad() and calculate the validation/test accuracy by using data from from the test dataloader."
      ],
      "metadata": {
        "id": "wimp3krs9vmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: validation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "val_accuracy = correct / total * 100\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "stL0ILUOoWrC",
        "outputId": "85fb3da7-e7e0-40f2-9637-48bd02d67ca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 73.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to adjust the learning rate of the optimizer"
      ],
      "metadata": {
        "id": "aVJ9jWqS9xkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] *= 0.5  # or 0.1"
      ],
      "metadata": {
        "id": "M7_epwjelhUw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to refactor the code block that calculates the test accuracy of a model into a function whose inputs are the model, the test dataloader and the device on which the model is."
      ],
      "metadata": {
        "id": "tfkM9sAF95rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(model, test_loader, device):\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # disable gradient computation\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "MRqtfkDXnZ5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_accuracy(model, test_loader, device))"
      ],
      "metadata": {
        "id": "nArFedG9nbyw",
        "outputId": "2d0cd678-8244-4be5-aa02-40629d834aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 61.40%\n",
            "61.395932014488714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to install and use the summary tool from torchinfo to get a summary of a models architecture, the input and output shapes of each layer and the number of parameters in each layer."
      ],
      "metadata": {
        "id": "vgBl8m2s_Gp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchinfo\n",
        "import torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "# Print a summary of our custom ViT model using torchinfo (uncomment for actual output)\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "aku63iPmnxG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d76943-1382-4acf-aee5-c06a44554422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "VGG (VGG)                                [32, 3, 224, 224]    [32, 7]              --                   Partial\n",
              "├─Sequential (features)                  [32, 3, 224, 224]    [32, 512, 7, 7]      --                   False\n",
              "│    └─Conv2d (0)                        [32, 3, 224, 224]    [32, 64, 224, 224]   (1,792)              False\n",
              "│    └─ReLU (1)                          [32, 64, 224, 224]   [32, 64, 224, 224]   --                   --\n",
              "│    └─MaxPool2d (2)                     [32, 64, 224, 224]   [32, 64, 112, 112]   --                   --\n",
              "│    └─Conv2d (3)                        [32, 64, 112, 112]   [32, 128, 112, 112]  (73,856)             False\n",
              "│    └─ReLU (4)                          [32, 128, 112, 112]  [32, 128, 112, 112]  --                   --\n",
              "│    └─MaxPool2d (5)                     [32, 128, 112, 112]  [32, 128, 56, 56]    --                   --\n",
              "│    └─Conv2d (6)                        [32, 128, 56, 56]    [32, 256, 56, 56]    (295,168)            False\n",
              "│    └─ReLU (7)                          [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
              "│    └─Conv2d (8)                        [32, 256, 56, 56]    [32, 256, 56, 56]    (590,080)            False\n",
              "│    └─ReLU (9)                          [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
              "│    └─MaxPool2d (10)                    [32, 256, 56, 56]    [32, 256, 28, 28]    --                   --\n",
              "│    └─Conv2d (11)                       [32, 256, 28, 28]    [32, 512, 28, 28]    (1,180,160)          False\n",
              "│    └─ReLU (12)                         [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
              "│    └─Conv2d (13)                       [32, 512, 28, 28]    [32, 512, 28, 28]    (2,359,808)          False\n",
              "│    └─ReLU (14)                         [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
              "│    └─MaxPool2d (15)                    [32, 512, 28, 28]    [32, 512, 14, 14]    --                   --\n",
              "│    └─Conv2d (16)                       [32, 512, 14, 14]    [32, 512, 14, 14]    (2,359,808)          False\n",
              "│    └─ReLU (17)                         [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
              "│    └─Conv2d (18)                       [32, 512, 14, 14]    [32, 512, 14, 14]    (2,359,808)          False\n",
              "│    └─ReLU (19)                         [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
              "│    └─MaxPool2d (20)                    [32, 512, 14, 14]    [32, 512, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
              "├─Sequential (classifier)                [32, 25088]          [32, 7]              --                   True\n",
              "│    └─Linear (0)                        [32, 25088]          [32, 4096]           102,764,544          True\n",
              "│    └─ReLU (1)                          [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Dropout (2)                       [32, 4096]           [32, 4096]           --                   --\n",
              "│    └─Linear (3)                        [32, 4096]           [32, 1024]           4,195,328            True\n",
              "│    └─ReLU (4)                          [32, 1024]           [32, 1024]           --                   --\n",
              "│    └─Dropout (5)                       [32, 1024]           [32, 1024]           --                   --\n",
              "│    └─Linear (6)                        [32, 1024]           [32, 7]              7,175                True\n",
              "========================================================================================================================\n",
              "Total params: 116,187,527\n",
              "Trainable params: 106,967,047\n",
              "Non-trainable params: 9,220,480\n",
              "Total mult-adds (Units.GIGABYTES): 243.20\n",
              "========================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 1902.38\n",
              "Params size (MB): 464.75\n",
              "Estimated Total Size (MB): 2386.40\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bdEqDaAi9CB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}